{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymysql\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.my_functions import analysis_functions as mybib\n",
    "from src.my_functions import lab_functions as lab\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import pymysql \n",
    "from sqlalchemy import create_engine\n",
    "from getpass import getpass  \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist \n",
    "\n",
    "- [x] get data\n",
    "- [x] check and clean data (nulls, fixing typos, outliers, distrubutions,...)\n",
    "- [x] data exploration\n",
    "- [x] select features\n",
    "- [x] check for multicolinearity\n",
    "- [ ] X/y split (feature/target) : X, y\n",
    "- [ ] train/test split : X_train, X_test, y_train, y_test\n",
    "- [ ] num/cat split : X_train_num, X_train_cat, X_test_num, X_test_cat\n",
    "- [ ] fit transformer on X_train_num\n",
    "- [ ] run transformer on X_train_num : X_train_normalized\n",
    "- [ ] run same transformer on X_test_num : X_test_normalized\n",
    "- [ ] fit encoder on X_train_cat\n",
    "- [ ] run encoder on X_train_cat : X_train_encoded\n",
    "- [ ] run same encoder on X_test_cat : X_test_encoded\n",
    "- [ ] concat X_train_normalized and X_train_encoded : X_train_transformed\n",
    "- [ ] choose model (LienarRegression on numeric target, LogisticRegression(=classification!) on categorical target)\n",
    "- [ ] fit (train) model in X_train_transformed : model\n",
    "- [ ] concat X_test_normalized and X_test_encoded : X_test_transformed\n",
    "- [ ] make predictions using X_test_transfomed : model.predict -> predictions\n",
    "- [ ] compute score using predictions and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection between Python and the Sakila database.\n",
    "\n",
    "password = getpass()\n",
    "\n",
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/sakila'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 1 \n",
    "query = '''\n",
    "SELECT f.title as film_title, c.name, f.rental_duration, f.rental_rate, f.rating, f.length, f.replacement_cost, count(DISTINCT r.rental_id) AS rental_count, count(DISTINCT r.inventory_id) AS inventory_count, \n",
    "    CASE\n",
    "        WHEN EXISTS (SELECT 1 FROM (SELECT DISTINCT f.title\n",
    "                                    FROM film f\n",
    "                                    JOIN inventory i USING (film_id)\n",
    "                                    JOIN rental r USING (inventory_id)\n",
    "                                    WHERE r.rental_date LIKE '2005-05%%')may where may.title = f.title) THEN 'Yes'\n",
    "        ELSE 'No'\n",
    "    END AS check_may\n",
    "FROM film f\n",
    "LEFT JOIN inventory i USING (film_id)\n",
    "LEFT JOIN rental r USING (inventory_id)\n",
    "LEFT JOIN film_category fc USING (film_id)\n",
    "JOIN category c USING (category_id)\n",
    "GROUP BY f.film_id, c.name;\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df.to_csv('data\\output.query1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 2 \n",
    "query = '''\n",
    "SELECT f.title as film_title, c.name, f.rental_duration, f.rental_rate, f.rating, f.length, f.replacement_cost, COUNT(DISTINCT fa.actor_id) AS actor_count, count(DISTINCT r.rental_id) AS rental_count, count(DISTINCT r.inventory_id) AS inventory_count, \n",
    "    CASE\n",
    "        WHEN EXISTS (SELECT 1 FROM (SELECT DISTINCT f.title\n",
    "                                    FROM film f\n",
    "                                    JOIN inventory i USING (film_id)\n",
    "                                    JOIN rental r USING (inventory_id)\n",
    "                                    WHERE r.rental_date LIKE '2005-05%%')may where may.title = f.title) THEN 'Yes'\n",
    "        ELSE 'No'\n",
    "    END AS check_may\n",
    "FROM film f\n",
    "LEFT JOIN inventory i USING (film_id)\n",
    "LEFT JOIN rental r USING (inventory_id)\n",
    "LEFT JOIN film_category fc USING (film_id)\n",
    "LEFT JOIN film_actor fa USING (film_id)\n",
    "JOIN category c USING (category_id)\n",
    "GROUP BY f.film_id, c.name;\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "display(df)\n",
    "df.to_csv('data\\output.query2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to run different queries for trying different versions of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "film1 = pd.read_csv('data\\output.query1', index_col=0)\n",
    "film2 = pd.read_csv('data\\output.query2',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used to discover data\n",
    "# mybib.firstLook(film1)\n",
    "# lab.discover_df(film1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score for Train = 0.81125\n",
      "Model Score for Test = 0.8\n",
      "[[ 39  28]\n",
      " [ 12 121]]\n"
     ]
    }
   ],
   "source": [
    "# With rental_count USING logisticRegression\n",
    "\n",
    "film1_v1 = film1.drop('film_title', axis = 1 )\n",
    "predictions, y_train = lab.split_encode_use_logisticRegression(film1_v1)\n",
    "# print(predictions)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score for Train = 0.74125\n",
      "Model Score for Test = 0.745\n",
      "[[ 24  34]\n",
      " [ 17 125]]\n"
     ]
    }
   ],
   "source": [
    "# Without rental_count USING logisticRegression\n",
    "\n",
    "film1_v2 = film1.drop(['rental_count', 'film_title'], axis = 1 )\n",
    "predictions, y_train = lab.split_encode_use_logisticRegression(film1_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score for Train = 0.80125\n",
      "Model Score for Test = 0.575\n",
      "[[ 13  52]\n",
      " [ 33 102]]\n"
     ]
    }
   ],
   "source": [
    "# Without rental_count USING neighbors\n",
    "predictions, y_train = lab.split_encode_use_neighbors(film1_v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
